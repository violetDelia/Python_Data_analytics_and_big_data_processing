#!/usr/bin/python
# -*- coding: UTF-8 -*-

from pyspark import SparkContext

sc = SparkContext()
rdd = sc.parallelize(["Spark", "hadoop", "hive"])
result = rdd.first()
print("rdd元素个数", result)

