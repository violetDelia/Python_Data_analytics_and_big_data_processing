#!/usr/bin/python
# -*- coding: UTF-8 -*-

from pyspark import SparkContext

sc = SparkContext()
rdd1 = sc.textFile("/bigdata/chapter/a_seafood.txt")

def func(item):
    data = item.split(":")
    return data[0], data[1]

rdd2 = rdd1.map(func)
result = rdd2.collect()

def f(item):
    print("当前元素是：", item)

[f(item) for item in result]
