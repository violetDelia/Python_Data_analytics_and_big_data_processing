#!/usr/bin/python
# -*- coding: UTF-8 -*-

from pyspark import SparkContext

sc = SparkContext()

rdd = sc.textFile("/spark/files/README.md")
rdd.flatMap(lambda line: line.split(" ")).map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y).saveAsTextFile(
    "/spark/files/filter_rdd/result.txt")
