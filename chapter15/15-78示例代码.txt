#!/usr/bin/python
# -*- coding: UTF-8 -*-

from pyspark import SparkContext

sc = SparkContext()
sc.setCheckpointDir("/spark/checkpoint")
rdd1 = sc.parallelize([1, 2, 3, 4, 5, 6])
rdd2 = rdd1.map(lambda x: x * 2)
rdd2.cache()
rdd2.checkpoint()
rdd2.sum()

