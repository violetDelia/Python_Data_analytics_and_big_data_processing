
import sys

from pyspark.sql import SparkSession
from pyspark.sql.functions import explode
from pyspark.sql.functions import split
from pyspark.sql.functions import window

if __name__ == "__main__":
    bootstrapServers = "localhost:9092"
    subscribeType = "subscribe"
    topics = "bigdata"
    windowSize = 10
    slideSize = 5
    windowDuration = '{} seconds'.format(windowSize)
    slideDuration = '{} seconds'.format(slideSize)

    spark = SparkSession.builder.appName("KafkaWordCount").getOrCreate()

    lines = spark.readStream.format("kafka").\
		option("kafka.bootstrap.servers", bootstrapServers) \
        .option(subscribeType, topics).option('includeTimestamp', 'true').load()

    words = lines.select(
        explode(split(lines.value, ' ')).alias('word'),
        lines.timestamp
    )
    windowedCounts = words.groupBy(
        window(words.timestamp, windowDuration, slideDuration),
        words.word
    ).count()

    query = windowedCounts.writeStream.outputMode('complete').format('console').start()
    query.awaitTermination()

	
	