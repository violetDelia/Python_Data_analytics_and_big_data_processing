
import sys

from pyspark.sql import SparkSession
from pyspark.sql.functions import split

if __name__ == "__main__":
    if len(sys.argv) != 4:
        print("""
        Usage: structured_kafka_wordcount.py <bootstrap-servers> <subscribe-type> <topics>
        """, file=sys.stderr)
        exit(-1)

    bootstrapServers = sys.argv[1]
    subscribeType = sys.argv[2]
    topics = sys.argv[3]
    spark = SparkSession.builder.appName("SumAmount").getOrCreate()
    lines = spark.readStream.format("kafka").\
        option("kafka.bootstrap.servers", bootstrapServers) \
        .option(subscribeType, topics).load().selectExpr("CAST(value AS STRING)")

    def split_vla(val):
        tmp = split(val, ":")
        return tmp[0].alias("name"), tmp[1].cast("float").alias("amount")

    words = lines.select(split_vla(lines.value))
    wordCounts = words.groupBy("name").sum("amount")
    query = wordCounts.writeStream.outputMode('complete').format('console').start()
    query.awaitTermination()

	
	