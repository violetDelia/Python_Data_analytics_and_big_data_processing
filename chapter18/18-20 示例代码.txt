# -*- coding: utf-8 -*-

from pyspark.sql import SparkSession
from pyspark.sql.types import StructField, StringType, StructType

spark = SparkSession.builder.getOrCreate()
file = "hdfs://localhost:9000/input/business_detail.txt"
rdd = spark.sparkContext.textFile(file)


def convert_data(line):
    lines = line.split(",")
    # 返回的三个数据分别是：商户名称，评分
    return lines[1], lines[2]


# 对数据去重然后排序
data = rdd.map(lambda line: convert_data(line)).distinct(). \
    sortBy(lambda x: x[1], ascending=False).collect()

schemaString = "name score"
fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]
schema = StructType(fields)
df = spark.createDataFrame(data, schema).limit(10)
df.show()


