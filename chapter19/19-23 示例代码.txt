#!/usr/bin/env python
# -*- coding:utf-8 -*-
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt

# 指定Mysql的配置
from pyspark.sql.types import StructField, StringType, StructType

options = {
    "url": "jdbc:mysql://localhost:3306/sparktest?useSSL=true",
    "driver": "com.mysql.jdbc.Driver",
    "dbtable": "(SELECT publishTime from travels) t1",
    "user": "root",
    "password": "root"
}
spark = SparkSession.builder.getOrCreate()
# 加载Mysql数据
data = spark.read.format("jdbc").options(**options).load()


# 将每一行的taglist转为列表
def convert_to_quarter(line):
    val = line[0].split("-")
    if val[1] in ["01", "02", "03"]:
        return "春季", 1
    elif val[1] in ["04", "05", "06"]:
        return "夏季", 1
    elif val[1] in ["07", "08", "09"]:
        return "秋季", 1
    elif val[1] in ["10", "11", "12"]:
        return "冬季", 1


zeroValue = 0
rdd = data.rdd.map(lambda line: convert_to_quarter(line)).foldByKey(zeroValue, lambda v, x: v + x)
schemaString = "quarter count"
fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]
schema = StructType(fields)
schema_data = spark.createDataFrame(rdd, schema).orderBy("count", ascending=False)

# 将数据转换为Pandas数据帧
result_pdf = schema_data.limit(5).toPandas()
# 设置matplotlib支持中文
plt.rcParams['font.family'] = ['sans-serif']
plt.rcParams['font.sans-serif'] = ['SimHei']
# colors=color, explode=explode,
plt.pie(result_pdf["count"], labels=result_pdf["quarter"], shadow=True, autopct='%1.1f%%')
plt.legend()
plt.show()

