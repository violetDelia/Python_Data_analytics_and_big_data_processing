
import datetime
import math

from pyspark.sql import SparkSession

spark = SparkSession \
    .builder \
    .appName("linajia") \
    .config("spark.mongodb.input.uri", "mongodb://127.0.0.1/test.lianjiadetail") \
    .config("spark.mongodb.output.uri", "mongodb://127.0.0.1/test.lianjiadetail") \
    .getOrCreate()

# 加载原始数据创建数据帧
mongodb_df = spark.read.format("com.mongodb.spark.sql.DefaultSource").load()

mongodb_df.createOrReplaceTempView("temp")
mongodb_compoundname_count_df = spark.sql(
    "select compoundname,sum(latest7) as counter from temp group by compoundname")

#在次注册一个临时表，用于排序
mongodb_compoundname_count_df.createOrReplaceTempView("temp1")
mongodb_compoundname_sort_df = spark.sql(
    "select compoundname,counter from temp1 order by counter desc limit 10")

#将spark数据帧转为pandas数据帧
df = mongodb_compoundname_sort_df.toPandas()
import matplotlib.pyplot as plt

plt.rcParams["font.sans-serif"] = ["SimHei"]

names = df["compoundname"]
counter = df["counter"]

#设置柱状条颜色、宽度
bar = plt.bar(range(10), height=counter, width=0.3, alpha=0.8, color="red")

#设置x坐标轴刻度和旋转角度
plt.xticks([i + 0.15 for i in range(10)], names, rotation=60)
plt.xlabel("小区名称")
plt.ylabel("带看次数")

for ba in bar:
    height = ba.get_height()
    plt.text(ba.get_x() + ba.get_width() / 2, height + 1, str(height),
	ha="center", va="bottom")

plt.show()


